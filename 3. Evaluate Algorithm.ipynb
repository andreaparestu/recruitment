{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <p style=\"text-align: center;\">Modul 3\n",
    "##  <p style=\"text-align: center;\">Evaluate Algorithm\n",
    "### <p style=\"text-align: center;\"> Human Capital Data Science (HCDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Algoritma *machine learning* yang akan digunakan untuk melakukan pemodelan output variable perlu dievaluasi tingkat akurasi dan kinerjanya. Salah satu metode yang digunakan dalam mengevaluasi algoritma tersebut adalah *resampling method*. \n",
    "\n",
    "# 3.1. Resampling Method\n",
    "Apabila output variable yang ingin dimodeling telah diketahui tujuannya, maka algoritma terbaik yang digunakan adalah algoritma yang dapat menggunakan **metode prediksi** untuk memprediksi hasil dari output variable tersebut.   \n",
    "\n",
    "Cara terbaik kedua adalah menggunakan teknik statistik yang disebut **metode resampling** yang memungkinkan untuk membuat perkiraan akurat untuk seberapa baik kinerja algoritma yang digunakan pada data baru yang tidak terlihat tujuan akhirnya. Resampling data tidak digunakan untuk meningkatkan akurasi *model machine learning*.  \n",
    "\n",
    "Dataset yang digunakan untuk memodelkan output variable (yang berikutnya disebut ***Training Data***) tidak dapat digunakan untuk menguji akurasi model yang telah dibuat (yang berikutnya disebut dengan ***Test Data***). \n",
    "\n",
    "Hal ini dapat mengakibatkan model tersebut menjadi ***overfitting***, artinya model statistik yang mengandung lebih banyak parameter daripada yang dapat dibenarkan oleh data. Hal ini dapat terjadi dikarenakan terdapat input variable yang diikut sertakan dalam pemodelan meskipun secara score pada *feature selection* dinilai cukup rendah. \n",
    "\n",
    "Apabila *test data* digunakan pada algoritma *machine learning* sebagai dataset yang digunakan untuk melatih algoritma (menggunakan *training data*), maka algoritma tersebut akan memiliki tingkat akurasi yang terlalu tinggi. Namun ketika diaplikasikan pada data riil, akuasi model machine learning dapat turun secara sinifikan. \n",
    "\n",
    "Data yang digunakan untuk membuat model ***Output Variable*** dapat menggunakan resampling  method sebagai berikut:\n",
    "\n",
    "- Split Data (Train and Test Sets).\n",
    "- k-fold Cross-Validation.\n",
    "- Leave One Out Cross-Validation.\n",
    "- Repeated Random Test-Train Splits\n",
    "\n",
    "Dalam bab ini akan dijelaskan bagaimana cara memperkirakan akurasi algoritma *machine learning* dengan menggunakan metode resampling dengan Python dan scikit-learn pada dataset HR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Split Data\n",
    "\n",
    "Metode paling sederhana yang dapat digunakan untuk mengevaluasi kinerja dari algoritma *machine learning* adalah dengan menggunakan *train data* yang berbeda dengan *test data*. Dataset akan dibagi (*split*) menjadi dua bagian data, yaitu train data dan test data. \n",
    "\n",
    "Train data digunakan untuk memodelkan dataset dan test data digunakan untuk menguji tingkat akurasi dari model yang dibentuk menggunakan train data. \n",
    "\n",
    "Ukuran split dapat bergantung pada ukuran dan spesifikasi dataset yang digunakan. Pada umumnya ukuran train data yang digunakan adalah dua per tiga bagian dari dataset atau 67% dataset, dan satu per tiga sisanya atau 33% data adalah test data untuk pengujian model.\n",
    "\n",
    "Teknik evaluasi algoritma dengan menggunakan split data ini dinilai sangat cepat dan ideal untuk dataset besar (jutaan catatan) di mana ada bukti kuat bahwa kedua bagian data tersebut merupakan perwakilan dari masalah yang mendasarinya model machine learning yang akan dibentuk. Hal ini juga akan membantu ketika Algoritma yang digunakan memiliki kecepatan yang rendah ketika melakukan pemodelan. \n",
    "\n",
    "Kelemahan dari teknik split data ini adalah dapat memiliki varian yang tinggi. Hal ini berarti bahwa perbedaan tingkat akurasi dari model yang dibentuk menggunakan traing data akan berbeda cukup signifikan dengan akurasi model yang dibentuk menggunakan test data. Dalam contoh di bawah ini, kami membagi set data HR ke dalam perpecahan 67% train data dan 33% test data yang akan digunakan untuk mengevaluasi akurasi model ***Logistic Regression***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.307%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using a train and a test set\n",
    "import pandas as pd\n",
    "\n",
    "# Load Library\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "# Pemisahaan ke dalam Train dan Test Data\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Training Model  \n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Scoring Model\n",
    "result = model.score(X_test, Y_test) * 100\n",
    "\n",
    "print(\"Accuracy: %.3f%%\" % result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terlihat tingkat akurasi dari model prediksi terhadap test data yang digunakan pada machine learning. \n",
    "\n",
    "#### Seed Setting \n",
    "\n",
    "Pada saat melakukan data sampling, hal lain yang perlu diperhatikan selain ukuran proporsional pembagian data, perlu juga diperhatikan mengenai pengaturan *seed* yang memeberikan informasi mengenai lokasi pengolahan data di memory computer. \n",
    "\n",
    "Penentuan *seed* tersebut bertujuan untuk memastikan bahwa algoritma machine learning menggunakan data yang sama dan dijalankan di lokasi memory yang sama, sehingga dapat dilakukan pembandingan tingkat akurasi dari semua model yang digunakan dalam pembuatan model machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 K-Fold Cross-Validation\n",
    "\n",
    "***Cross-Validation*** adalah pendekatan yang dapat digunakan untuk memperkirakan kinerja algoritma machine learning pada sampling dataset dengan pembagian menjadi beberapa bagian data (disebut ***k-fold***). Setiap bagian data disebut dengan ***fold***. Artinya apabila dataset dibagi menjadi 5 bagian dataset, maka disebut ***5-fold cross validation***. \n",
    "\n",
    "#### CEK BAHASA\n",
    "Algoritma ini dilatih pada k − 1 lipatan dengan yang ditahan dan diuji pada lipatan punggung yang dipegang. Ini diulang sehingga setiap kali lipat dari dataset diberi kesempatan untuk menjadi set back test yang diadakan. Setelah menjalankan validasi silang, Anda mendapatkan skor kinerja k yang dapat Anda simpulkan menggunakan mean dan deviasi standar. Hasilnya adalah perkiraan kinerja algoritma yang lebih andal pada data baru. Ini lebih akurat karena algoritma dilatih dan dievaluasi beberapa kali pada data yang berbeda. Pilihan k harus memungkinkan ukuran setiap partisi pengujian cukup besar untuk menjadi sampel yang wajar dari masalah, sementara memungkinkan pengulangan yang cukup dari evaluasi tes-kereta dari algoritma untuk memberikan perkiraan yang adil dari kinerja algoritma pada data yang tidak terlihat. . Untuk dataset berukuran kecil dalam ribuan atau puluhan ribu rekaman, nilai k 3, 5, dan 10 adalah umum. Dalam contoh di bawah ini, kami menggunakan 10 kali lipat validasi silang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.516% (Std : 14.792%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi Model menggunakan K-Fold Cross Validation\n",
    "\n",
    "# Load Library\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "# Pemisahaan ke dalam Train dan Test Data\n",
    "test_size = 0.33\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "mean = results.mean()*100.0\n",
    "std = results.std()*100.0\n",
    "print(\"Accuracy: %.3f%% (Std : %.3f%%)\" % (mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anda dapat melihat bahwa kami melaporkan baik mean dan standar deviasi ukuran kinerja. Ketika meringkas ukuran kinerja, itu adalah praktik yang baik untuk meringkas distribusi langkah-langkah, dalam hal ini dengan asumsi distribusi Gaussian kinerja (asumsi yang sangat wajar) dan merekam mean dan standar deviasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Leave One Out Cross-Validation\n",
    "Anda dapat mengkonfigurasi validasi silang sehingga ukuran lipatan adalah 1 (k diatur ke jumlah observasi dalam kumpulan data Anda). Variasi validasi silang ini disebut crossvalidasi kiri-satu-keluar. Hasilnya adalah sejumlah besar ukuran kinerja yang dapat diringkas dalam upaya untuk memberikan perkiraan yang lebih masuk akal tentang keakuratan model Anda pada data yang tidak terlihat. Kelemahannya adalah ia bisa menjadi prosedur komputasi yang lebih mahal daripada k-fold cross-validation. Dalam contoh di bawah ini kami menggunakan validasi silang cuti satu"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Evaluasi Model menggunakan Leave One Out Cross Validation\n",
    "\n",
    "# Load Library \n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "# Leave One Out Cross Validation\n",
    "loocv = LeaveOneOut()\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=loocv)\n",
    "\n",
    "mean = results.mean()*100.0\n",
    "std = results.std()*100.0\n",
    "print(\"Accuracy: %.3f%% (Std : %.3f%%)\" % (mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anda dapat melihat dalam standar deviasi bahwa skor memiliki lebih banyak varians daripada k-fold cross-validation results yang dijelaskan di atas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Repeated Random Test-Traing Splits\n",
    "Another variation on k-fold cross-validation is to create a random split of the data like the train/test split described above, but repeat the process of splitting and evaluation of the algorithm multiple times, like cross-validation. This has the speed of using a train/test split and the reduction in variance in the estimated performance of k-fold cross-validation. You can also repeat the process many more times as needed to improve the accuracy. A down side is that repetitions may include much of the same data in the train or the test split from run to run, introducing redundancy into the evaluation. The example below splits the data into a 67%/33% train/test split and repeats the process 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.711% (Std : 0.459%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Shuffle Split Cross Validation\n",
    "import pandas as pd\n",
    "\n",
    "# Load Library\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "# Pemisahaan ke dalam Train dan Test Data\n",
    "n_splits = 10\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "\n",
    "# Shuffle Splits Cross Validation\n",
    "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "mean = results.mean()*100.0\n",
    "std = results.std()*100.0\n",
    "print(\"Accuracy: %.3f%% (Std : %.3f%%)\" % (mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita dapat melihat bahwa dalam hal ini distribusi ukuran kinerja setara dengan k-fold cross-validation di atas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penentuan Teknik yang Tepat\n",
    "Bagian ini mencantumkan beberapa tips untuk mempertimbangkan teknik resampling apa yang digunakan dalam situasi yang berbeda.\n",
    "\n",
    "- Umumnya k-fold cross-validation adalah standar emas untuk mengevaluasi kinerja algoritma pembelajaran mesin pada data yang tidak terlihat dengan k disetel ke 3, 5, atau 10.\n",
    "- Menggunakan pemisahan kereta / tes baik untuk kecepatan ketika menggunakan algoritma yang lambat dan menghasilkan perkiraan kinerja dengan bias yang lebih rendah saat menggunakan dataset besar.\n",
    "- Teknik seperti meninggalkan-satu-keluar lintas-validasi dan pemisahan acak berulang dapat menjadi perantara yang berguna ketika mencoba untuk menyeimbangkan varians dalam kinerja diperkirakan, kecepatan pelatihan model dan ukuran dataset.\n",
    "\n",
    "Saran terbaik adalah bereksperimen dan ï nd teknik untuk masalah Anda yang cepat dan menghasilkan perkiraan kinerja yang wajar yang dapat Anda gunakan untuk membuat keputusan. Jika ragu, gunakan 10 kali lipat validasi silang."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ringkasan\n",
    "Dalam bab ini Anda menemukan teknik statistik yang dapat Anda gunakan untuk memperkirakan kinerja algoritme pembelajaran mesin Anda, yang disebut resampling. Secara khusus, Anda belajar tentang:\n",
    "\n",
    "- Split Data.\n",
    "- Cross-Validation.\n",
    "- Leave One Out Cross-Validation.\n",
    "- Repeated Random Test-Train Splits.\n",
    "\n",
    "Pada bagian berikutnya Anda akan belajar bagaimana Anda dapat mengevaluasi kinerja klasifikasi dan algoritma regresi menggunakan seperangkat metrik yang berbeda dan dibangun dalam laporan evaluasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Classification Performance Metrics\n",
    "Metrik yang Anda pilih untuk mengevaluasi algoritma pembelajaran mesin Anda sangat penting. Pilihan metrik mempengaruhi bagaimana kinerja algoritma pembelajaran mesin diukur dan dibandingkan. Mereka mempengaruhi bagaimana Anda menimbang pentingnya karakteristik yang berbeda dalam hasil dan pilihan akhir Anda dari algoritma mana yang harus dipilih. Dalam bab ini Anda akan menemukan cara memilih dan menggunakan metrik kinerja pembelajaran mesin yang berbeda dengan Python dengan scikit-learn. Mari mulai.\n",
    "\n",
    "Dalam pelajaran ini, berbagai metrik evaluasi algoritme diperlihatkan untuk masalah-masalah pembelajaran mesin tipe klasifikasi dan regresi.Âˆ Untuk metrik klasi ﬁ kasi, Indian Pima onset set data diabetes digunakan sebagai demonstrasi. Ini adalah masalah kasi ﬁ kasi biner di mana semua variabel input adalah numerik.Âˆ Untuk metrik regresi, dataset Boston House Price digunakan sebagai demonstrasi. ini adalah masalah regresi di mana semua variabel input juga numerik.\n",
    "\n",
    "Semua resep mengevaluasi algoritme yang sama, Regresi Logistik untuk klasifikasi dan Linear Regression untuk masalah regresi. Alat ukur lintas-keabsahan 10 kali lipat digunakan untuk mendemonstrasikan setiap metrik, karena ini adalah skenario yang paling mungkin akan Anda gunakan ketika menggunakan metrik evaluasi algoritme yang berbeda. Sebuah peringatan dalam resep-resep ini adalah validasi silang. \n",
    "\n",
    "Fungsi skor lintas val digunakan untuk melaporkan kinerja dalam setiap resep. Ini memungkinkan penggunaan metrik skor yang berbeda yang akan dibahas, tetapi semua nilai dilaporkan sehingga mereka dapat diurutkan dalam urutan menaik (skor terbesar adalah yang terbaik). Beberapa metrik evaluasi (seperti kesalahan kuadrat rata-rata) adalah skor yang menurun secara alami (skor terkecil adalah yang terbaik) dan dengan demikian dilaporkan sebagai negatif oleh fungsi validasi silang. Lintas skor (). Ini penting untuk diperhatikan, karena beberapa skor akan dilaporkan negatif bahwa dengan definisi tidak akan pernah negatif. Saya akan mengingatkan Anda tentang peringatan ini saat kita bekerja melalui pelajaran. Anda dapat mempelajari lebih lanjut tentang metrik kinerja algoritme pembelajaran mesin yang didukung oleh scikit-learn pada halaman Evaluasi model: mengukur kualitas prediksi2. Mari lanjutkan dengan metrik evaluasi.\n",
    "\n",
    "Klasifikasi masalah mungkin merupakan jenis yang paling umum dari masalah pembelajaran mesin dan karena itu ada banyak sekali metrik yang dapat digunakan untuk mengevaluasi prediksi untuk masalah ini. Di bagian ini kami akan meninjau cara menggunakan metrik berikut:\n",
    "- Classiﬁcation Accuracy.\n",
    "- Logarithmic Loss.\n",
    "- Area Under ROC Curve.\n",
    "- Confusion Matrix.\n",
    "- Classiﬁcation Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Classification Accuracy\n",
    "Klasifikasi akurasi adalah jumlah prediksi yang benar yang dibuat sebagai rasio dari semua prediksi yang dibuat. Ini adalah metrik evaluasi paling umum untuk masalah klasifikasi, ini juga yang paling disalahgunakan. Ini benar-benar hanya cocok ketika ada jumlah pengamatan yang sama di setiap kelas (yang jarang terjadi) dan bahwa semua prediksi dan kesalahan prediksi sama pentingnya, yang sering tidak terjadi. Di bawah ini adalah contoh perhitungan akurasi klasifikasi.# Cross Validation Classification Accuracy\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "mean = results.mean()*100.0\n",
    "std = results.std()*100.0\n",
    "print(\"Accuracy: %.3f%% (Std : %.3f%%)\" % (mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.516% (Std : 14.792%)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Accuracy\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "mean = results.mean()*100.0\n",
    "std = results.std()*100.0\n",
    "print(\"Accuracy: %.3f%% (Std : %.3f%%)\" % (mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anda dapat melihat bahwa rasio dilaporkan. Ini dapat dikonversi menjadi persentase dengan mengalikan nilai dengan 100, memberikan skor akurasi sekitar 89.516% akurat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Logarithmic Loss\n",
    "Kerugian logaritmik (atau logloss) adalah metrik kinerja untuk mengevaluasi prediksi probabilitas keanggotaan ke kelas tertentu. Probabilitas skalar antara 0 dan 1 dapat dilihat sebagai ukuran kepercayaan untuk prediksi oleh suatu algoritma. Prediksi yang benar atau salah dihargai atau dihukum secara proporsional dengan keyakinan prediksi. Di bawah ini adalah contoh perhitungan logloss untuk prediksi regresi logistik pada onset Pima Indian dari dataset diabetes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Cross Validation Classification LogLoss\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=8)\n",
    "model = LogisticRegression()\n",
    "scoring = 'neg_log_loss'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "mean = results.mean()*100.0\n",
    "std = results.std()*100.0\n",
    "print(\"Logloss: %.3f%% (Std : %.3f%%)\" % (mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Area Under ROC Curve\n",
    "Area di bawah ROC Curve (atau AUC untuk pendek) adalah metrik kinerja untuk masalah-masalah klasifikasi biner. AUC mewakili kemampuan model untuk membedakan antara kelas positif dan negatif. Area seluas 1,0 merupakan model yang membuat semua prediksi sempurna. Area seluas 0,5 merupakan model yang sebagus acak. ROC dapat dipecah menjadi sensitivitas dan spesi ﬁ k kota. Masalah klasi ﬁ kasi biner adalah benar-benar sebuah trade-oï¬ antara sensitivitas dan spesi ﬁ kasi.ˆ Sensitivitas adalah tingkat positif sebenarnya yang disebut recall. Ini adalah jumlah instance dari kelas positif (ive) yang benar-benar diprediksi dengan benar.\n",
    "Spesifisitas juga disebut tingkat negatif yang benar. Apakah jumlah instance dari kelas negatif (kedua) yang benar-benar diprediksi dengan benar.Contoh di bawah ini memberikan demonstrasi menghitung AUC."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Cross Validation Classification ROC AUC\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'roc_auc'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(\"AUC: %.3f (%.3f)\") % (results.mean(), results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4. Confusion Matrix\n",
    "Matriks kebingungan adalah presentasi berguna dari keakuratan model dengan dua atau lebih kelas. Tabel menyajikan prediksi pada hasil x-axis dan akurasi pada sumbu y. Sel-sel tabel adalah jumlah prediksi yang dibuat oleh algoritma pembelajaran mesin. Misalnya, algoritme pembelajaran mesin dapat memprediksi 0 atau 1 dan setiap prediksi sebenarnya adalah 0 atau 1. Prediksi untuk 0 yang sebenarnya 0 muncul di sel untuk prediksi = 0 dan aktual = 0, sedangkan prediksi untuk 0 yang sebenarnya 1 muncul di sel untuk prediksi = 0 dan aktual = 1. Dan seterusnya. Di bawah ini adalah contoh menghitung matriks kebingungan untuk satu set prediksi oleh Regresi Logistik pada onset Pima Indian dari dataset diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3184   90]\n",
      " [ 254  429]]\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Confusion Matrix\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meskipun array dicetak tanpa judul, Anda dapat melihat bahwa sebagian besar prediksi jatuh pada garis diagonal dari matriks (yang merupakan prediksi yang benar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5. Classification Report\n",
    "Perpustakaan scikit-learn menyediakan laporan kenyamanan ketika bekerja pada masalah klasifikasi untuk memberi Anda gambaran cepat tentang keakuratan model menggunakan sejumlah ukuran. Fungsi laporan klasifikasi () menampilkan presisi, penarikan, skor F1 dan dukungan untuk setiap kelas. Contoh di bawah ini menunjukkan laporan tentang masalah klasifikasi biner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.97      0.95      3274\n",
      "        1.0       0.83      0.63      0.71       683\n",
      "\n",
      "avg / total       0.91      0.91      0.91      3957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Report\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Spot-Check Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Spot-Checking*** adalah cara untuk menganalisa hasil kinerja dari algoritma Machine Learning dalam menyelesaikan permasalahan Machine Learning.  \n",
    "\n",
    "Pada bagian ini akan dibahas mengenai enam algoritma Machine Learning yang digunakan untuk memeriksa Classification Problem dengan *Python - scikit-learn*, dengan urutan sebagai berikut:\n",
    "1. Cara spot-check algoritma pembelajaran mesin pada masalah klasiﬁkasi.\n",
    "2. Cara spot-check dua algoritma klasifikasi linier\n",
    "3. Cara spot-check empat algoritma klasifikasi nonlinier\n",
    "\n",
    "#### Linear Algorithm\n",
    "Dalam melakukan Spot-Checking dapat menggunakan dua ***Linear Machine Learning algorihtm*** berikut:\n",
    "- Logistic Regression .\n",
    "- Linear Discriminant Analysis\n",
    "\n",
    "#### Non-Linear Algorithm\n",
    "Dalam melakukan Spot-Checking juga dapat menggunakan empat ***Non-Linear Machine Learning algorihtm*** berikut:\n",
    "- *k*-Nearest Neighbors\n",
    "- Naive Bayes\n",
    "- Classification dan Regression Trees\n",
    "- Support Vector Machines\n",
    "\n",
    "Setiap resep ditunjukkan pada onset Pima Indian dari dataset Diabetes. Suatu uji harness menggunakan 10-fold cross-validation digunakan untuk mendemonstrasikan bagaimana spot-check setiap algoritma pembelajaran mesin dan pengukuran akurasi berarti digunakan untuk menunjukkan kinerja algoritma. Resepnya berasumsi bahwa Anda tahu tentang setiap algoritma pembelajaran mesin dan bagaimana menggunakannya. Kami tidak akan masuk ke API atau parameterisasi setiap algoritma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. Linear Machine Learning Algorihtms\n",
    "Bagian ini menunjukkan resep minimal untuk bagaimana menggunakan dua algoritma pembelajaran mesin linier: regresi logistik dan analisis diskriminan linier.\n",
    "\n",
    "#### 3.3.1.1. Logistic Regression\n",
    "Regresi logistik mengasumsikan distribusi Gaussian untuk variabel input numerik dan dapat memodelkan masalah klasifikasi biner. Anda dapat membangun model regresi logistik menggunakan kelas LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8951626355296082\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "# Penggunaan K-Fold Cross Validation\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "\n",
    "# Pemodelan Machine Learning\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1.2. Linear Discriminant Analysis (LDA)\n",
    "***Linear Discriminant Analysis atau LDA*** adalah teknik statistik untuk klasifikasi biner dan multiclass. Itu juga mengasumsikan distribusi Gaussian untuk variabel input numerik. Anda dapat membangun model LDA menggunakan LinearDiscriminantAnalysis class2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8944954128440367\n"
     ]
    }
   ],
   "source": [
    "# LDA Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "# Penggunaan K-Fold Cross Validation\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "\n",
    "# Pemodelan Machine Learning\n",
    "model = LinearDiscriminantAnalysis()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "# Rata-rata akurasi dari se\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. Nonlinear Machine Learning Algorithm\n",
    "Pada bagian ini akan ditunjukkan cara bagaimana menggunakan empat ***non-linear machine learning algorithm***:\n",
    "1. k-Nearest Neighbors\n",
    "2. Naive Bayes\n",
    "3. Classification dan Regression Trees\n",
    "4. Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2.1. k-Nearest Neighbors (k-NN)\n",
    "***k-Nearest Neighbors algorithm (atau KNN)*** menggunakan metrik jarak untuk menemukan ***k*** yang paling mirip dalam train data untuk contoh baru dan mengambil hasil rata-rata dari tetangga sebagai prediksi. Anda dapat membuat model KNN menggunakan kelas ***KNeighborsClassifier***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9216847372810676\n"
     ]
    }
   ],
   "source": [
    "# KNN Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "# Penggunaan K-Fold Cross Validation\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2.2. Naive Bayes\n",
    "***Naive Bayes*** menghitung probabilitas masing-masing kelas dan probabilitas bersyarat dari masing-masing kelas yang diberikan setiap nilai input. \n",
    "\n",
    "Probabilitas ini diperkirakan untuk data baru dan dikalikan bersama, dengan asumsi bahwa semuanya independen (asumsi sederhana atau naif). Ketika bekerja dengan data bernilai nyata, distribusi Gaussian diasumsikan mudah memperkirakan probabilitas untuk variabel input menggunakan Fungsi Kepadatan Probabilitas Gaussian. Anda dapat membuat model Naive Bayes menggunakan ***GaussianNB class***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8997497914929106\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "# Penggunaan K-Fold Cross Validation\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = GaussianNB()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2.3. Classification and Regression Trees\n",
    "Klasifikasi dan Regresi Pohon (pohon CART atau hanya keputusan) membangun pohon biner dari data pelatihan. Titik perpecahan dipilih dengan rakus dengan mengevaluasi setiap atribut dan setiap nilai dari setiap atribut dalam data pelatihan untuk meminimalkan fungsi biaya (seperti indeks Gini). Anda dapat membuat model CART menggunakan kelas DecisionTreeClassifier5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9754795663052545\n"
     ]
    }
   ],
   "source": [
    "# CART Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "# Penggunaan K-Fold Cross Validation\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = DecisionTreeClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2.4. Support Vector Machines\n",
    "Support Vector Machines (atau SVM) mencari garis yang paling baik memisahkan dua kelas. Contoh-contoh data yang paling dekat dengan garis yang paling baik memisahkan kelas disebut vektor dukungan dan pengaruh di mana garis ditempatkan. SVM telah diperpanjang untuk mendukung beberapa kelas. Yang paling penting adalah penggunaan fungsi kernel yang berbeda melalui parameter kernel. Fungsi Radial Basis yang kuat digunakan secara default. Anda dapat membuat model SVM menggunakan kelas SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9332777314428691\n"
     ]
    }
   ],
   "source": [
    "# SVM Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = pd.read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "# Penggunaan K-Fold Cross Validation\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = SVC()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ringkasan\n",
    "Dalam bab ini Anda menemukan 6 algoritme pembelajaran mesin yang dapat Anda gunakan untuk mengecek masalah klasi ﬁ kasi Anda dengan Python menggunakan scikit-learn. Secara khusus, Anda belajar cara memeriksa dua algoritma pembelajaran mesin linear: Logistic Regression and Linear Discriminant Analysis. Anda juga belajar bagaimana memeriksa empat algoritma nonlinear: k-Nearest Neighbors, Naive Bayes, Klasifikasi dan Regression Trees dan Support Vector Machines.\n",
    "\n",
    "Dalam pelajaran berikutnya Anda akan menemukan bagaimana Anda dapat menggunakan pengecekan di tempat pada masalah pembelajaran mesin regresi dan berlatih dengan tujuh algoritme regresi yang berbeda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.  Perbandingan Kinerja Machine Learning Algorithm\n",
    "\n",
    "Dalam penggunaan algoritma *machine learning* diperlukan perbandingan kinerja dari berbagai algoritma yang terdapat pada *Scikit Learn - Pyhton* agar diperoleh algoritma dengan kinerja terbaik untuk machine learning project yang dikerjakan. \n",
    "\n",
    "Beberapa hal yang akan dipelajari pada bagian ini adalah: \n",
    "1. Bagaimana cara merumuskan percobaan untuk membandingkan beberapa algoritma *machine learning* secara bersamaan.\n",
    "2. Template yang dapat digunakan kembali untuk mengevaluasi kinerja beberapa algoritme pada suatu dataset.\n",
    "3. Bagaimana melaporkan dan memvisualisasikan hasil ketika membandingkan kinerja algoritma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1. Pemilihan Algoritma *Machine Learning* Terbaik\n",
    "\n",
    "Pada bagian sebelumnya telah dilakukan berbagai proses awal pemilihan algoritma *machine learning* dengan melakukan evaluasi kinerja menggunakan teknik *resampling - performance validation*, perbandingan *performance metrics*, dan juga melakukan *spot-checking* pada beberapa algoritma tersebut. \n",
    "\n",
    "Beberapa algoritma *Machine Learning* yang terpilih pada proses tersebut akan dilakukan perbandingan karakteristik kinerjanya pada bagian ini dengan menggunakan visualisasi kinerja menggunakan dataset baru. Karakteristik kinerja yang ingin dibandingkan dari berbagai algoritma tersebut adalah rata-rata, varian dan properti lain dari distribusi akurasi masing-masing algoritma dengan *scikit-learn (python)*.\n",
    "\n",
    "Dalam contoh di bawah ini akan dilakukan evaluasi kinerja dari beberapa algoritma Classification Machine Learning yang berbeda, yaitu sebagai berikut:\n",
    "\n",
    "- Logistic Regression.\n",
    "- Linear Discriminant Analysis.\n",
    "- k-Nearest Neighbors.\n",
    "- Classiﬁcation and Regression Trees.\n",
    "- Naive Bayes.\n",
    "- Support Vector Machines\n",
    "\n",
    "Dataset yang digunakan adalah data HR (*datahr.csv*). Prosedur ***10-Fold Cross Validation*** digunakan untuk mengevaluasi kinerja setiap algoritma tersebut pada *seed* yan sama untuk memastikan bahwa pemisahan test data dan train data yang digunakan tidak berbeda pada pengujian setiap algoritma tersebut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.895163 (0.147925)\n",
      "LDA: 0.894495 (0.129199)\n",
      "KNN: 0.921685 (0.068381)\n",
      "CART: 0.975646 (0.023871)\n",
      "NB: 0.899750 (0.042594)\n",
      "SVM: 0.933278 (0.090987)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perbandingan Akurasi Beberapa Algoritma Machine Learning \n",
    "\n",
    "# Load library\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load Dataset\n",
    "nama = ['PUAS', 'EVAL', 'PROJ', 'KB', 'DK', 'KK', 'PROM', 'DIV', 'GAJI', 'STAT'] \n",
    "dataset = read_csv(\"datahr.csv\")\n",
    "array = dataset.values\n",
    "\n",
    "# Pemisahaan Array menjadi Array Input Variable and Array Output Variable\n",
    "X = array[:,0:9]\n",
    "Y = array[:,9]\n",
    "\n",
    "# Persiapan Model \n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# Evaluasi Kinerja Setiap Algoritma Machine Learning \n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "\tkfold = KFold(n_splits=10, random_state=7)\n",
    "\tcv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "\n",
    "# Perbandingan Akurasi Algoritma - Boxplot \n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Perbandingan Distributsi Algorithm')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contoh ini juga menyediakan *box-whisker plot* yang menunjukkan penyebaran skor akurasi di setiap *fold* pada proses *cross-validation* dari setiap algoritma yang digunakan. Dari hasil ini terlihat kinerja algoritma terbaik adalah CART dan SVM untuk dataset HR yang digunakan.\n",
    "\n",
    "#### Ringkasan\n",
    "Dalam bab ini telah dipaparkan cara mengevaluasi beberapa algoritma *machine learning* yang berbeda pada kumpulan data dalam Python dengan scikit-learn. Anda belajar bagaimana menggunakan kedua alat uji yang sama untuk mengevaluasi algoritme dan cara meringkas hasil secara numerik dan menggunakan kotak dan kumis petak. Anda dapat menggunakan resep ini sebagai template untuk mengevaluasi beberapa algoritme pada masalah Anda sendiri.\n",
    "\n",
    "Dalam pelajaran ini Anda belajar bagaimana membandingkan kinerja algoritma pembelajaran mesin satu sama lain. Tetapi bagaimana jika Anda perlu mempersiapkan data Anda sebagai bagian dari proses perbandingan. Dalam pelajaran berikutnya Anda akan menemukan Saluran Pipa di scikit-belajar dan bagaimana mereka mengatasi masalah umum kebocoran data ketika membandingkan algoritma pembelajaran mesin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
